% Journal:
%   Journal of Ambient Intelligence and Smart Environments (JAISE), IOS Press
%   Web Intelligence and Agent Systems: An International Journal (wias)
% Latex 2e
% Test file iosart2c.tex

%[seceqn,secfloat,secthm,crcready]

% options: wias, jaise
\documentclass{iosart2c}


\usepackage[T1]{fontenc}
\usepackage{times}%

%\usepackage{natbib}
\usepackage[numbers]{natbib}

\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{dcolumn}
%\usepackage{endnotes}
\usepackage{graphics}


%========================== MY PACKAGES ================================%

%pseudocode
\usepackage{algorithm}
\usepackage{algpseudocode}

%draw artificial neural networks
\usepackage{neuralnetwork}
\usepackage{xpatch}
\makeatletter
\xpatchcmd{\linklayers}{\nn@lastnode}{\lastnode}{}{}
\xpatchcmd{\linklayers}{\nn@thisnode}{\thisnode}{}{}
\makeatother

%figures
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{caption}
\usepackage{subcaption} %subimagenes

%math
\usepackage{amsmath,amssymb,amsfonts,amsthm} %for mathematics fonts 
\usepackage{stmaryrd}

%For ORCID logo
\usepackage{svg}



%========================== MY PACKAGES ================================%




\newcolumntype{d}[1]{D{.}{.}{#1}}


\firstpage{1} \lastpage{5} \volume{1} \pubyear{2009}


\begin{document}
\begin{frontmatter}                           % The preamble begins here.

%
%\pretitle{Pretitle}
\title{Evolving neural networks for threat process detection with autoencoder-based fitness functions.}

\runningtitle{Evolving neural networks for threat process detection using autoencoder to build a fitness function.}
%\subtitle{Subtitle}


\author[A,B]{\fnms{Henry D.} \snm{Navarro H.}\thanks{Corresponding author. Henry D. Navarro H., E-mail: contact@henrynavarro.org.}},
\author[B]{\fnms{Héctor} \snm{Bullejos}},
\author[B]{\fnms{Carmelo} \snm{Garrido}}
and
\author[B]{\fnms{Elena} \snm{Naranjo}}
\runningauthor{H. Navarro et al.}
\address[A]{Research and Development Lab, Vision Analytics, Avenida de Europa 19, 28224, Pozuelo de Alarcón, Madrid,\\ Spain\\
E-mail: contact@henrynavarro.org}
\address[B]{Research and Development Labs, Capgemini Engineering, Calle Campezo, 1, 28022, Madrid, Spain.\\
E-mail: engineering@capgemini.com}

\begin{abstract}
Threat detection is one of the main focus of several studies in the cybersecurity area and it has become one of the main focuses of researchars. Threat may occur in any forms like viruses or phishing attack with different purposes. Once the intruder has filtered into our system, the primary step is to try to detect the malicious process to prevent it from causing damage to our system. In this paper, we present a real time hybrid method using deep neural networks to obtain a fitness function and evolutionary algorithms to detect and kill malicious processes on a simulated network system.
\end{abstract}

\begin{keyword}
Neuroevolution \sep Genetic Algorithms \sep Threat detection \sep Autoencoders
\end{keyword}

\end{frontmatter}



\section{Introduction}
Deep neuroevolution, autoencoders, and cybersecurity are three interrelated areas that have the potential to significantly impact the field of information security. Deep neuroevolution refers to the use of evolutionary algorithms to optimize artificial neural networks, which can be used to improve the accuracy and efficiency of various machine learning tasks. Autoencoders, on the other hand, are a type of neural network that can be used to learn efficient representations of data, and have been applied to a wide range of problems including dimensionality reduction, anomaly detection, and data compression. In the context of cybersecurity, these techniques can be used to improve the ability of systems to detect and mitigate various cyber threats, such as malware, phishing attacks, and network intrusions.\\

In order to simulate a network, attack computers with a malicious process and have an environment under control, we have created a virtual network with 20 virtual instances using open source softwares. We start from the fact that the malicious process has already infiltrated in our system either using ransomware, social engineering or any other common technique in modern cybersecurity. We collect the system data of these virtual instances using open source libraries. This data will be used to train neural networks, detect and kill the malicious process using evolutionary algorithms based on deep neuroevolution.\\

Evolve neural networks has been used in different tasks but mainly in train neural networks to play video games \cite{deepGA}, \cite{neuroevolution1}, \cite{neuroevolution2}, although there are other applications as music generation \cite{neuroevolution3} and modelling biological phenomena \cite{neuroevolution4}. These neural network training methods rely on genetic algorithm operations to obtain the best agent to perform a specific task. However, there is not too much research related to this topic and cybersecurity as we will see in the section \ref{relatedwork}.\\

Any evolutionary algorithm needs a fitness function in order to determine what agents or individuals are the best in each generation. In our case, the best agents will be those who ``kill'' the malicious process in each generation which will result in instances which take their ``normal states''. In order to characterize this normal state, we use an ingenuous solution for this need, using an artificial neural network called autoencoder. This neural network will learn the healthy state of each instance and using the mean square error (MSE) between the inputs and outputs of the neural networks, we will know how infected is the instance, so the closer this value to zero the more healthy is the state of the instance, then we will use the best agents following this criteria. Finally, using a single command of any Linux system, we kill the process who is negatively affecting our virtual instance.


\section{Related work}\label{relatedwork}

Autoencoders are neural networks that consist of an encoder to generate a vector of features in the latent space (of smaller dimension) and from the input data and a decoder, which seeks to reconstruct the input data from this latent vector \cite{autoencoders_nlp1}. This type of neural networks are used in anomaly detection \cite{anomaly1, anomaly3},\cite{anomaly4}, natural language processing \cite{autoencoders_nlp1} and dimensionality reduction \cite{dimred1}, \cite{dimred2}.\\

Other researchers have proved that autoencoders can be used to detect other threats like Denial of Services \cite{autoencoderdos}. On their paper, they use an autoencoder to classify different denial of services attacks. However, our objective is not only to classify the state of a virtual machine between two states: healthy and infected but, to get a measure to quantify how infected a virtual instance is. For this, we train this neural network just with the healthy state data and we will use the mean square error (MSE) as a fitness function to choose the best agents in threat detection, the closer this value to zero the more healthy is the state of the instance.\\

As for the topic of deep neuroevolution, there is no direct application in the area of cybersecurity. However, other researchers have applied genetic algorithms to improve network security \cite{GA1, GA2, GA3}. In most of these papers, a binary gene is reached out in order to block or detect certain network attacks such as Syn-Flood, Smurf and others, for this purpose, common operations in genetic algorithms such as selection, crossover, mutation are used.\\

Different investigations in malware detection have been carried out using deep neural networks for them \cite{malwarednn1, malwarednn2,malwarednn3}, however, these researchers train their models using algorithms that involve gradients. In this paper, we present another way to train a neural network that can detect a malicious process that creates idle tasks that affect common system values like CPU, memory RAM, hard drive, among others. This process is detected and killed in order to return the healthy state in a virtual instance.

\section{Methodology}

\subsection{Network simulation}

The virtual network to emulate the attacks was built and simulated based on the fact that an intruder had already obtained access to the network and already represents an internal threat, that is, the file that executes the malicious process is already found in the virtual instances. We have virtualized a network architecture with 20 instances using an a network orchestrator with 4 physical machines.\\

These instances send their system data to a NoSQL database where we monitor the variables that we explain in the next section and these are the features we use to develop our models.

\subsection{Dataset}\label{dataset_autoencoder}

The dataset has been generated first extracting the normal traffic of a virtualized environment to get the ``healthy'' data that a system could have, to get this normal behaviour we used a software tool able to extract 97 features related mainly with cpu, memory ram or usage of hard drive that we split into 10 main groups. Then, the two cyber attacks have been sent to this virtualized network and extracting the data to obtain two new classes: A malicious process developed by us that we will call \textit{Logic Bomb}, which is a process that affects the regular parameters like CPU, memory, disk creating idle processes by this task.

\subsubsection{Central Processing Unit (CPU) features}
They refer to the load characteristics that the CPU of the instance may have. A malicious process acting on the instances is expected to drive CPU usage across the entire instance in order to crash it.\\


\subsubsection{Core features}

These features are similar to CPU variables, with the difference that they are disaggregated by core. Due to how virtualized instances have been created (1GB of memory, 1 core only), these variables are expected to have a high correlation with the CPU variables.


\subsubsection{Disk Input/Output (Disk I/O) features}

Disk I / O operations include both read and write or Input / Output (usually defined in KB / s) involving a physical disk. In simple words, it is the speed with which the data transfer takes place between the hard disk drive and RAM, or basically it measures the input / output time of the active disk. It is a performance measure and is therefore used to characterize storage disks as HDD, SSD, and SAN. A malicious process is expected to constantly perform read and write operations to cause a saturation of this hardware. \\

\subsubsection{Entropy}
Entropy available on the system.

\subsubsection{Filesystem}

This set of features refer to file system statistics on disk. Some malicious processes create an infinite loop that creates files indefinitely in order to saturate it. \\

\subsubsection{Memory Swap}

When the physical memory or RAM in our system is full, we proceed to use the \textit{Memory Swap} in our systems. In this process, the inactive pages of our memory are moved to the swap space, creating more memory resources. This space is especially useful when a system does not have RAM; however, the swap space is located on the hard drive and is therefore slower to access. Therefore it should not be considered as an alternative to RAM. As indicated above, a malicious process is expected to crash RAM memory and from there, begin to consume the resources of swap memory.


\subsubsection{Memory hugepages}

Hugepages are useful in managing virtual memory on Linux systems. As the name implies, they help manage large pages in memory that are larger than the default (usually 4KB). Hugepages is useful for both 32-bit and 64-bit configurations. Hugepages sizes can range from 2MB to 256MB, depending on the kernel version and hardware architecture. A malicious process is expected to increase the values of this variable. \\



\subsubsection{Socket summary}
These variables refer to the summary of open socket metrics in the system. A socket is nothing more than a communication channel between two programs that run on different computers or even on the same computer. Malicious processes seeking to attack the network are expected to affect these variables.  \\

\section{Anomaly detection classification for fitness function}\label{autoencoder_section}

An autoencoder neural network is an unsupervised learning algorithm that applies backpropagation, configuring the target values to be equal to the inputs. That is, the response variable that the machine learning algorithm tries to learn is such that $y^{(i)} = x^{(i)} $, where $x^{(i)} = \{x^{(1)}, x^{(2)}, \ldots, x^{(n)} \} $ are the input variables detailed in section \ref{dataset_autoencoder} and the appendix \ref{appx_variables}.\\

\subsection{Autoencoder architecture}\label{autoencoder_architecture}

An autoencoder consists of two parts, an encoder that we will denote as $ f_{\phi} $ and a decoder that we denote with $ g_{\theta} $. An autoencoder neural network will be denoted as $ h_{W, b} = g_\theta \circ f_\phi$, where $W$ and $b$ are the weight matrix and the vector ``bias'' or bias of the neural network and $h$ is the final transformation function or hypothesis. \\

We will denote $n_l$ as the number of layers in our network. In our case, we have taken a network with three hidden layers, therefore $n_l=5$. We denote the $l$-th layer as $L_l$, therefore $L_1$ is the input layer and $L_{n_l}$ is the denoting the output layer. We also denote the parameters $(W,b)=(W^{(i)},b^{(i)})$, with $i=1,\ldots,5$ and where $W^{(l)}$ are the weight matrices (weights) of each layer and $b^{(i)}$ the bias vector (bias) associated with the connections between the unit (neuron) $j$ in layer $l$, and unit $i$ in layer $l+1$. Likewise, we denote $f_{\cdot l}$ the activation function that ``connects'' layer $l-1$ with the layer $l$. And finally, we denote $s_i$ as the number of neurons (units) of the layer $i$. \\


Due to the high dimensionality of the dataset that we have used, a selection of variables is made, which we explain in the results section \ref{results_autoencoder}. However, we have selected the number of neurons in such a way that in the encoder part $s_i=\left\llbracket\frac{s_{i-1}}{2}\right\rrbracket$, while for the part of the decoder $s_i=\left\llbracket 2\times s_{i-1} \right\rrbracket$, where $\llbracket \cdot \rrbracket$ represents the integer part of a real number. \\

Like any neural network, it requires activation functions that allow connecting all the units (neurons) of each layer. For our autoencoder, we have selected the activation functions as follows:
\begin{eqnarray*}
f_{\cdot 2} &=& \tanh(x)=\frac{e^{x}-e^{-x}}{ e^{x}+e^{-x}},\\
f_{\cdot 3} &=& ReLU(x) = x^+ = \max(0, x),\\
f_{\cdot 4} &=& f_{\cdot 2} = \tanh(x)=\frac{e^{x}-e^{-x}}{ e^{x}+e^{-x}},\\
f_{\cdot 5} &=& f_{\cdot 3} = ReLU(x) = x^+ = \max(0, x)\\
\end{eqnarray*}

We will write $a_i^{(l)}$ to denote the activation (the value at the output) of the unit $i$ in the layer $l$. For $l=1$, we use $a_i^{(1)}=x_i$ to denote the $i$-th input. That is to say,
\begin{eqnarray*}
z^{(l)}&=&W^{(l-1)}a^{(l-1)}+b^{(l-1)}\\
a^{(l)}&=&f_{\cdot l}(z^{(l)})
\end{eqnarray*}
Graphically, the architecture of the autoencoder can be seen in figure \ref{fig:architecture_autoencoder}. \\


\begin{figure*}[h!]
\centering
\begin{neuralnetwork}[height=9.5,nodespacing=1cm,nodesize=20pt,  layerspacing=3.6cm][h]

    %comandos previos
    \newcommand{\x}[2]{\ifthenelse{\equal{#2}{0}}{$b_0$}{\ifnum #2=8 $x_n$ \else $x_#2$ \fi}} %si es el índice cero, entonces le asignas b0, sino si es la neurona 8, lo cambias por el índice n
    \newcommand{\ffirst}[2]{\ifthenelse{\equal{#2}{0}}{$b_1$}
    {\ifnum #2=4 $a_{\frac{n}{2}}^{(2)}$ \else $a_{#2}^{(2)}$ \fi}}
    \newcommand{\fsecond}[2]{\ifthenelse{\equal{#2}{0}}{$b_2$}
    {\ifnum #2=3 $a_{\frac{n}{4}}^{(3)}$ \else $a_{#2}^{(3)}$ \fi}}
    \newcommand{\fthird}[2]{\ifthenelse{\equal{#2}{0}}{$b_3$}
    {\ifnum #2=4 $a_{\frac{n}{2}}^{(4)}$ \else$a_{#2}^{(4)}$ \fi}}
    \newcommand{\xhat}[2]{\ifthenelse{\equal{#2}{0}}{$b_0$}{\ifnum #2=8 $\hat{x}_n$ \else $\hat{x}_#2$ \fi}}
    
    %red neuronal
    \hspace{-0.75cm}
    \inputlayer[count=8, bias=true,exclude={7},title=Input\\layer, text=\x]
    \hiddenlayer[count=4, bias=true,exclude={3},title={$L_2$\\$f_{\cdot 2} = \tanh(x)$}, text=\ffirst] 
    \linklayers[not from={7},not to={3}] %para que no dibuje la flecha desde la neurona 7
    \hiddenlayer[count=3, bias=true,exclude={2}, title={$L_3$\\$f_{\cdot 3} = ReLU(x) $}, text=\fsecond]
    \linklayers[not from={3},not to={2}]
    \hiddenlayer[count=4, bias=true,exclude={3}, title={$L_4$\\$f_{\cdot 4} = \tanh(x)$}, text=\fthird]
    \linklayers[not from={2},not to={3}]
    \outputlayer[count=8, exclude={7},title={Output layer\\$\hat{x}_i=a_{i}^{(5)}$}, text=\xhat]
    \linklayers[not to={7},not from={3}]
    
    
     % draw dots
    \path (L0-6) -- node{$\vdots$} (L0-8);
    \path (L1-2) -- node{$\vdots$} (L1-4);
    \path (L2-1) -- node{$\vdots$} (L2-3);
    \path (L3-2) -- node{$\vdots$} (L3-4);
    \path (L4-6) -- node{$\vdots$} (L4-8);
    
\end{neuralnetwork}
\caption{Architecture of the neural network of the autoencoder type used for anomaly detection}
\label{fig:architecture_autoencoder}
\end{figure*}


The autoencoder is trained with the well-known algorithm called stochastic gradient descent  with 60 epochs. The next step is to determine the decision threshold from which the instances will be considered as infected. That is, values greater than this threshold will be infected instances or instances with anomalous behavior. For this, we use the mean square error between the input data and the output of the trained autoencoder as we show in the Algorithm \ref{autoencoder_anomalias}.\\


\begin{algorithm}[h!]
\caption{Anomaly detection algorithm with the autoencoder}\label{autoencoder_anomalias}
\textbf{Input:} Validation dataset $X_{val}=\{x^{(1)},\ldots,x^{(n)}\}$, autoencoder $h_{W,b}=g_\theta \circ f_\phi$.\\ Train dataset with normal behaviour  $X$, Anomaly train data $x^{(i)}$ $i = 1,...,N$, threshold $\alpha$\\
\begin{algorithmic}[1]
\State $\phi$, $\theta$ $\xleftarrow{}$ Train the autoencoder with normal data $X$
\For{i=1 to N}
    \State $MSE(i) = \lVert x^{(i)} - g_\theta(f_\phi(x^{(i)})\rVert_2^2$ \Comment{Mean Square Error (MSE)}
    \If{$MSE(i) > \alpha$}
        \State$x^{(i)}$ is an anomaly
        \State pred$\xleftarrow{}$1
    \Else 
        \State$x^{(i)}$ is not an anomaly
        \State pred$\xleftarrow{}$0
    \EndIf
\EndFor
\end{algorithmic}
\textbf{Output:} Vector of classifications.\\
\end{algorithm}


On the other hand, to achieve our objective, we will have to determine what is that threshold from which we will say that there is an anomaly. To find this decision threshold, we seek to test for all mean square error in our training data (healthy) and determine which of them is the optimal one that maximizes the accuracy in the confusion matrix, as shown in the Algorithm. \ref{obtener_umbral}.


\begin{algorithm}
\caption{Obtaining the optimal $\alpha$ threshold for anomaly detection}\label{obtener_umbral}
\textbf{Input:} Train dataset $X_{train}=\{X_{train}^{(1)},\ldots,X_{train}^{(n)}\}$, Validation dataset $X_{val}=\{X_{val}^{(1)},\ldots,X_{val}^{(n)}\}$, autoencoder $h_{W,b}$.\\

\begin{algorithmic}
\State $\hat{X}_{train} \xleftarrow{} h_{W,b}(X_{train})$ \Comment{Evaluate the training data in the autoencoder.}
\State $Max\_MSE\_{train}\xleftarrow{}\max\left(\sum_{i=1}^n\left(X_{train}^{(i)}-\hat{X}_{train}^{(i)}\right)^2\right)$ \Comment{From the above list we choose the highest root mean square error.}
\State $\hat{X}_{val} \xleftarrow{} h_{W,b}(X_{val})$ \Comment{Same for validation data.}
\State $MSE_{val}\xleftarrow{}\sum_{i=1}^n\left(X_{val}^{(i)}-\hat{X}_{val}^{(i)}\right)^2$ 
\State $partition\xleftarrow{} Max\_MSE\_{train}/1000$
\State Initialize $\alpha$, $Accuracy_{optimal}$, $MSE_{optimal}$ with zero values.\\



\For{i=1 to 1000} \Comment{1000 threshold partitions are tested, from 0 to $Max\_MSE\_{train}$ and the best is saved:}
    \State $y_{val}^{(i)}\xleftarrow{}anomaly(MSE_{val},\alpha)$\Comment{Apply the Algoritmh \ref{autoencoder_anomalias} (vector of 1's y 0's)}
    \State $Accuracy_{current}\xleftarrow{}$ Get the accuracy from $(y_{val},y_{val}^{(i)})$
        \If{$Accuracy_{current}>Accuracy_{optimal}$} 
            \State $Accuracy_{optimal}\xleftarrow{}Accuracy_{current}$
            \State $\alpha\xleftarrow{}MSE_{current}$
        \EndIf
    \State $MSE_{current}\xleftarrow{}MSE_{current}+partition$
\EndFor\\
\end{algorithmic}
\textbf{Output:} Optimal threshold $\alpha$.\\
\end{algorithm}


\newpage



\section{Evolutionary algorithm approach}

\subsection{Features for agents}\label{variables}

To characterize those malicious processes in an instance, we study some features that may anticipate this result. These variables to be studied do not directly describe the instance, but rather the processes that are running in it, because, we do not have a dataset of processes classified as malicious. The hybrid machine learning and genetic algorithms must be able to detect and mitigate it, using the correct order just as any algorithm would do. In our case, we have separated the variables into four groups.\\


\subsubsection{File descriptors}

The file descriptor is a non-negative integer that uniquely identifies the files opened in a session. Each process is allowed to have up to nine file descriptors open at one time. The bash shell reserves the first three file descriptors (0, 1, and 2) for special purposes \cite{shell_scripting2}. 

\subsubsection{Central Processing Unit (CPU)}

They refer to the load characteristics that the CPU may have for each process. A malicious process acting on the instances is expected to drive up CPU usage in order to crash it.\\

\subsubsection{Memory}

This set of variables refer to the RAM memory consumption that each process performs. A malicious process should carry out a high consumption of these type of resources. 


\subsubsection{Temporal features}

As the name indicates, in this set are the variables that are related to time.\\

\subsection{Architecture of the agents (neural networks) of the population} \label{arquitectura_agents}

Following the notation in the section \ref{autoencoder_architecture}, our neural network has parameters $(W,b)=(W^{(1)},b^{(1)},W^{(2)},b^{(2)})$. That is, we have $W^{(1)} \in \mathbb {R}^{15x8}$, while $ W^{(2)} \in \mathbb {R}^{1x15}$. We use a softmax function as a network hypothesis. Thus, we will hypothesize $ h: \mathbb {R}^ {2} \rightarrow [0,1] ^ 2 $ as the softmax function of the last layer of each neural network: 
\begin{equation}\label{softmax}
h_{W,b}(x)=\left(\frac{e^{a_1^{(3)}}}{\sum_{j=1}^2 e^{a_j^{(3)}}},\frac{e^{a_2^{(3)}}}{\sum_{j=1}^2 e^{a_j^{(3)}}}\right)
\end{equation}


Therefore, for the logical bomb attack, $n^{[2]}=2$ because what we will obtain will be a probability vector as follows:
\begin{align*}
    (P_{\texttt{no}},P_{\texttt{kill}})=(&P(\texttt{no kill process } | \\
									    & X=x_1,\ldots,x_n),\\
                                         &P(\texttt{kill process } | \\
                                         & X=x_1,\ldots,x_n))
\end{align*}

such that  $P_{\texttt{no}}+P_{\texttt{kill}}=1$, where $x_i$ are the monitored variables for that process, defined in section \ref{variables}. So the activation function in the last hidden layer will be given by the function softmax \ref{softmax}. \\

In our case, the neural network that we have chosen can be seen in the diagram we can see in figure \ref{fig:architecture_autoencoder}.\\

\begin{figure*}[h!]
\centering
\begin{neuralnetwork}[height=8,nodespacing=1cm,nodesize=20pt,  layerspacing=3.6cm][h]

    %comandos previos
    \newcommand{\x}[2]{\ifthenelse{\equal{#2}{0}}{$b_0$}
    {\ifnum #2=4 $x_n$ \else $x_#2$ \fi}} %si el índice=cero, asigna b0, sino si es la neurona 8, lo cambias por el índice n
    \newcommand{\ffirst}[2]{\ifthenelse{\equal{#2}{0}}{$b_1$}
    {\ifnum #2=6 $a_{15}$ \else $a_{#2}^{(2)}$ \fi}}
    \newcommand{\y}[2]{$y_#2$}
    
    %red neuronal
    \inputlayer[count=4, bias=true,exclude={3},title=Input\\layer, text=\x]
    \hiddenlayer[count=6, bias=true,exclude={5},title={$L_2$\\$f_{\cdot 2} = reLU(x)$}, text=\ffirst]
    \linklayers[not from={3},not to={5}] %para que no dibuje la flecha desde la neurona 7
    \outputlayer[count=2, title={Output layer\\$softmax(x)$}, text=\y]
    \linklayers[not from={5}]
    
    
     % draw dots
    \path (L0-2) -- node{$\vdots$} (L0-4);
    \path (L1-4) -- node{$\vdots$} (L1-6);

\end{neuralnetwork}
\label{fig:arquitectura_agente}
\caption{Neural network architecture used for attack mitigation.}
\end{figure*}


\subsection{Evolving Neural Networks}

Therefore, each individual/agent is a neural network known as a multilayer perceptron (MLP) with $n^{[0]}=8$ \textit{input units} (neurons in the input layer), due to the variables of the processes to analyze (See section \ref{variables}), $n^{[1]}=15$ \textit{hidden units} (neurons in the hidden layer) this with the intention that in the hidden layer we have twice as many neurons as in the input layer, and $n^{[2]}=2$ \textit{output units} (neurons in the output layer).\\

\subsection{Initialization}\label{sec_init}

We will have for each generation, $\lambda$ neural networks (initial population size), where $\lambda$ will be the maximum number of instances that can be virtualized in our environment according to computer resources. The initialization of the weights $W_{ij}^{[l]}$ of the $\lambda$ neural networks is done using the general rule to establish the weights in a neural network, which is to establish them in such a way that they are close from scratch without being too small. For this, we define the function \textsc{HeWeights} as follows: \\


\begin{algorithm}[h!]
\caption{He Initialization}\label{Hefunction}
\begin{algorithmic}[1]
\Function{HeWeights}{agent}
\State n $\gets$ number of nodes of layer $l$  \Comment{agent is the neural network}
\State y $\gets$ $\frac{1.0}{\sqrt{n}}$
\State agent.weights $\gets$ $U(-y,y)$ \Comment{random numbers with distribution $U(-y,y)$}
\State return agent 
\EndFunction
\end{algorithmic}
\end{algorithm}

Therefore, the initialization operation of the deep neuroevolution algorithm is a configuration of $\lambda$ MLP's with with a weights initialization $W_{ij}^{[l]}$ with uniform distribution as seen in the algorithm \ref{init}:


\begin{algorithm}[h!]
\caption{Initialization}\label{init}
\hspace*{\algorithmicindent} \textbf{Input:} population size or number of agents $\lambda$, number of neurons in input each layer: $n^{[0]}, n^{[1]}, n^{[2]}$, weights initialization function $\phi$.
\begin{algorithmic}[1]
\State agents $\gets$ \text{empty list}
\For{$i = 1,\ldots,\lambda$}
\State init\_agent $\gets$ create a MLP with $n^{[0]}, n^{[1]}, n^{[2]}$ neurons in each layer and ReLU as activation function.
\State init\_agent $\gets$ \textsc{HeWeights}(init\_agent) \Comment{function that returns weights using He's initialization.}
\State agents[i] $\gets$ init\_agent \Comment{add to list the agent initialized}
\EndFor
\end{algorithmic}
\hspace*{\algorithmicindent} \textbf{Output:} $\lambda$ neural networks with He's initialization.
\end{algorithm}




\subsubsection{Evaluation}\label{evaluacion}

This operation indicates ``how good'' are the agents that result from the initialization or after each operation (selection, crossing, mutation, elitism). For this, the pretained autoencoder with healthy data. This is where the autoencoder steps in to provide a measure through mean square error as we have detailed in Section \ref{autoencoder_section}.\\

The goal of this model is to be able to provide a measure that allows determining anomalies in the data of the virtual instances. For this we have based on the \textit{mean square error} (MSE) between the input data ${x_1,x_2,x_3,\ldots}$ of the autoencoder (instance data) and the data at the output of the autoencoder ${\hat{x}_1,\hat{x}_2,\hat{x}_3,\ldots}$. \\

Therefore, the evaluation operator or \textit{fitness function} of the Deep Neuroevolution algorithm will be given by: \\
\begin{equation}\label{fitness}
    fitness=MSE=\frac{1}{n^{[0]}}\sum_{i=1}^{n^{[0]}} (x_i-\hat{x}_i)^2
\end{equation}
where ${x_1,x_2,x_3,\ldots}$ are the input data of the autoencoder (instance data) and ${\hat{x}_1,\hat{x}_2,\hat{x}_3,\ldots}$ is the data in output the output of the autoencoder. \textbf{The closer the fitness function is to zero, the better the agent will be.} \\



\subsubsection{Selection and Crossing}

After the evaluation, those individuals/agents (from the $n$ neural networks) with the best fitness (\ref{fitness}) should be selected, in our case, a fitness closer to zero will be an indicator of better agent. \\

Now, within the operations that we will define are two of the most important: Selection and Crossing. For the first operation, the name is quite intuitive and it seeks to select the best agents according to the fitness function (the closer to zero, the better). We will select the best $n_{top}$ agents where
\begin{equation}\label{n_top}
    n_{top}=\left\llbracket\frac{-1+\sqrt{1+4\cdot2\cdot \lambda}}{2}\right\rrbracket+1
\end{equation}

and $\llbracket x\rrbracket$ is the \textit{floor} function. This is because the crossover operation needs to reproduce $\lambda-1$ agents from the best ones, which requires a number $n_{top}$ such that $\sum_{i=1}^{n_{top}} i=\lambda$. Therefore, the equation \ref{n_top} is nothing more than the solution of the equation $\frac{n_{top}(n_{top}+1)}{2}=\lambda$, where $\lambda$ is the number of agents in the initial population $P_0$. \\

The crossing operation we have defined from the best $n_{top}$ seeks to create a population of size $\lambda-1$  crossing the weights $W_{ij}$ of an agent ``father'' and several ``mother'' agents with a probability of $0.5$. This is nothing more than a Bernoulli event, where a coin is tossed, if a result comes out, the son will have the weight $W_{ij}$ of the father, otherwise he will keep the weight $W_{ij}$ of the mother.




\begin{algorithm}
\caption{Selection and Crossover}\label{selec_cross}
\begin{algorithmic}[1]
\State $n_{top}=\left\llbracket\frac{-1+\sqrt{1+4\cdot2\cdot\lambda}}{2}\right\rrbracket+1$
\Function{Selection and crossover}{agents,$n_{top}$}
\State agents\_top= select best $n_{top}$ agents from the list agents.
\State children= empty list
\State max\_id = 1 \Comment{Initialize a loop end parameter}
\While {\texttt{max\_id<=n-1}}
\For{\texttt{i = 1,\ldots,max\_id}}
\State mother=agents\_top[i] \Comment{Neural network mother}
\State father=agents\_top[max\_id] \Comment{Neural Network father}
\For{each unit of neural network $W_{ij}^{[parent]}$}
\State coin=$U(0,1)$ \Comment{Get random number with uniform distribution}
\State \textbf{If} coin$\leq0.5$ \textbf{then}
\State \hspace{0.5cm} $W_{ij}^{[children]}$=$W_{ij}^{[father]}$ \Comment{Update each weight of each unit}
\State \textbf{Else}
\State \hspace{0.5cm} $W_{ij}^{[children]}$=$W_{ij}^{[mother]}$ \Comment{Update each weight of each unit}
\EndFor
children[i]=new\_children
\EndFor
\EndWhile
\State \textbf{Return} children
\EndFunction
\end{algorithmic}
\end{algorithm}



\subsubsection{Mutation}

In evolutionary algorithms it is convenient that for the new descendants formed by selection and crossing, some of their genes (in our case the weights or the neurons) can be subjected to a mutation with a low random probability of a change. This implies that some weights of the neurons of the initial $\lambda$ neural networks, will be modified with a ``small'' change that depends on a value known as \textit{mutation power} \cite{deepGA}. We will call this hyperparameter $\sigma$. \\

The mutation occurs to maintain diversity within the population, without this operation, the values of the weights $W_{ij}$ of the neural networks (agents) would only maintain the values obtained from initialization.\\

That is, we are adding to the weights $W_{ij}$ of the units (neurons) of each neural network, a value $\sigma\cdot \mathcal{N}(0,1)$ with $\sigma=0.02$ . For properties of the normal distribution, we will have to simply add a value with distribution $\mathcal{N}(0,0.02^2)=\mathcal{N}(0,0.0004)$. This very small value will prevent the weights from having extreme changes but at the same time it will allow these weights to vary beyond the values they have taken in the initialization operation (Algorithm \ref{init}). This value $\sigma$ could be considered as the analogous value to the learning rate in the case of stocasthic gradient descent. Therefore we define the following algorithm: \\



\begin{algorithm}[h!]
\caption{Mutation} \label{mutation}
\begin{algorithmic}[1]
\State $\sigma=0.02$ \Comment{mutation power}
\State mutated\_children= empty list
    \Function{mutation}{children} \Comment{As input it needs the list returned by selection and crossover operation (Algorithm \ref{selec_cross})}
        \For{i = 1,\ldots,total of children}
            \For{each weight $W_{ij}$ of unit of neural network}
                \State $r_{norm}$= get random number $\mathcal{N}(0,1)$
                \State $W_{ij}$=$W_{ij}+\sigma\cdot r_{norm}$ \Comment{Update each weight of each unit}
                \State new\_children=assign to this neural network the weights $W_{ij}$.
            
\EndFor \\
        \State mutated\_children[i]=new\_children
\EndFor
\State \textbf{Return} mutated\_children
\EndFunction
\end{algorithmic}
\end{algorithm}



\subsubsection{Elitism}

Elitism in our case refers to a selection of the neural network which is the best agent able to mitigate an attack. From the $n_{top}$ top agents that are selected (\ref{n_top}), we perform what is known as \textit{tournament elitism}. That is, we tested a total of $m$ times each agent (neural network) in the virtualized environment with the infected instances and the average of the \textit{fitness} \ref{fitness} is calculated for these $m$ times. This average will determine which is the best after the $m$ executions. Finally, the elite agent (neural network) is added to the list of child agents (mutated\_children), thus keeping us the best of all \textbf{unmutated} and without any alteration, allowing us to keep the one with the best mitigation characteristics of attacks. \\



\begin{algorithm}[h!]
\caption{Elitism}\label{elitismo}
\begin{algorithmic}[1]
\State $n_{top}=\left\llbracket\frac{-1+\sqrt{1+4\cdot2\cdot \lambda}}{2}\right\rrbracket+1$
\Function{Elitism}{mutated\_children,agents,$n_{top}$}
\State agents\_top= select best $n_{top}$ agents from the list agents.
\For{i = 1,..., $n_{top}$}
    \State agent\_test = agents[i]
    \State fitness\_agent= empty list
    \State j=1
    \Repeat
        \State test the agent in the virtualized environment
        \State fitness\_agent[j]=calculate the fitness using \State the autoencoder \ref{fitness}.
        \State j=j+1
    \Until{j=$m$}
\EndFor
\State fitness\_mean[i]=$\frac{1}{m}\sum^m_{j=1}$fitness\_agent[j]
\State elite=select agent with best fitness\_mean
\State new\_generation=add elite to mutated\_children
\State \textbf{Return} new\_generation
\EndFunction
\end{algorithmic}
\end{algorithm}

On the other hand, we must penalize when the agent decides to kill all the processes of the instance, otherwise the neural network will learn to reduce the MSE given by the autoencoder based on kill all the processes of the instance, so when the agent applies \texttt{kill} to all processes, the command will be changed to not kill any processes. Finally the scheme of the neuroevolution algorithm can be seen in Figure \ref{fig:architecture_autoencoder}.


\begin{figure}[h!]
\includegraphics[width=0.51\textwidth]{figs/neuroevolution/diag_neuroevolution.eps}
\vspace{-0.5cm}
\caption{Neuroevolution algorithm flow.}
\label{fig:diagneuroevolution}
\end{figure}




\section{Experiments and Results}
In this section, we present the results of the experiments carried out following the proposed algorithms in the previous sections. 

%\subsection{Experiments Setup Network}


\subsection{Feature selection}

Due to the high dimensionality of the dataset, it is necessary to discard certain features in order to improve the perfomance of the model. Firstly, to reduce the number of variables, a previous study of each variable was made, comparing the results between the different states of each instance. The first variables to delete were those are not affected in either state of the virtual instance, i.e, they keep the same value throughout the data extraction. With this, 26 of the 97 initial variables were deleted. \\

It is well known that multicollinearity in data considerably reduces the predictive power of many machine learning models. Despite the fact that an autoencoder is not a linear model, it is convenient to reduce this high dimensionality of the data in any case and an important measure to do so, is through correlation. \\



\begin{table*}[h!]
\begin{tabular}{ccc}
\hline
Variable 1 & Variable 2 & Correlation \\ \hline
load 15 & load norm 15 & 1.0\\ 
load norm 1 & load 1 & 1.0\\ 
memory used bytes & memory free & 1.0\\ 
memory actual used bytes & memory actual free & 1.0\\ 
load norm 5 & load 5 & 1.0\\ 
filesystem free & filesystem available & 0.99\\ 
memory used bytes & memory used pct & 0.991\\ 
memory free & memory used pct & 0.99\\ 
memory actual free & memory actual used pct & 0.99\\ 
memory actual used bytes & memory actual used pct & 0.99\\ 
entropy available bits & entropy pct & 0.99\\ 
core idle pct & cpu idle pct & 0.99\\ 
core system pct & cpu system pct & 0.99\\ 
core user pct & cpu user pct & 0.99\\ 
core nice pct & cpu nice pct & 0.99\\ 
cpu iowait pct & core iowait pct & 0.99\\ 
diskio io time & diskio write count & 0.99\\ 
process summary sleeping & process summary total & 0.98\\ 
diskio write bytes & diskio io time & 0.98\\ 
cpu total pct & core idle pct & 0.98\\ 
cpu total pct & cpu idle pct & 0.98\\ 
fsstat total size used & fsstat total size free & 0.987\\ 
diskio io time & diskio write time & 0.98\\ 
fsstat total size used & filesystem used bytes & 0.97\\ 
diskio write bytes & diskio write count & 0.96\\ 
filesystem used bytes & filesystem used pct & 0.96\\ 
fsstat total size free & filesystem used pct & 0.96\\ 
diskio write count & diskio write time & 0.95\\ 
fsstat total size free & filesystem used bytes & 0.94\\ 
diskio iostat write request per sec & diskio iostat busy & 0.94\\ 
filesystem free & filesystem free files & 0.92\\ 
filesystem available & filesystem free files & 0.92\\ 
diskio iostat await & diskio iostat write await & 0.92\\ 
socket summary all count & socket summary udp all count & 0.91\\ 
socket summary tcp all established & socket summary tcp all count & 0.917\\ 
diskio iostat queue avg size & diskio iostat busy & 0.90\\ \hline

\end{tabular}
\label{tabla:sencilla}
\caption{Pearson correlation ($\rho$) table for variables with correlation coefficient $\rho>0.90$.}
\end{table*}

In this way, it was first established that variables were strongly related to each other (a pearson's correlation coefficient higher than 0.7) and once the relationships were obtained, a study was carried out on the variables themselves, that is, the definition of the variables themselves. Thus, if two variables explained the same information, one of them would be discarded. It was also tried to have at least one representative variable for each module in order to have more complete information on the system. After this study, a total of 58 out of 97 variables were discarded.


\subsection{Results}


The results show that it is possible to determine the state of a instance using autoencoders and also detect malicious processes that affect the normal behaviour of a computer. So the results are presented in two steps: anomaly detection results and evolutionary algorithms for neural networks.


\subsubsection{Autoencoder model results}\label{results_autoencoder}

The autoencoder model was trained with only the healthy state of the data using the stochastic gradient descent algorithm with 60 epochs. The mean square error was monitored during the training process, the results are shown in Figure \ref{fig:autoencoder_variable_selected}.\\



\begin{figure}[h!]
\centering
\includegraphics[scale=0.56]{figs/autoencoder/final_autoencoder.eps}
\caption{Nº epochs vs. $MSE$. Mean square error for a trained (Train) and validated (Validation) data for the autoencoder neural network with data from healthy machines after feature selection.}
\label{fig:autoencoder_variable_selected}
\end{figure}

After the model is trained, it is necessary to determine the decision threshold from which the state of the machine is considered an anomaly, for this, the Algorithm \ref{obtener_umbral} was used. Which gave as a result an optimal threshold $\alpha\approx 1.1945\ldots$, the closer value to this the state of the instance is, the greater the consideration will be as a healthy state of the instance. Therefore, the best ``parents'' will be those that after killing the processes, lead to the state of the instances at values closer to this $\alpha$. After the data extraction of anomaly values, the results of this analysis can be seen in Figure \ref{fig:reconstuction_LB}.\\

\begin{figure}[h!]
\centering
\includegraphics[scale=0.56]{figs/autoencoder/reconstruccion_error_LB.eps}
\caption{Threshold decision from the mean square error (MSE). The red line represents the threshold decision $\alpha\approx1.1945\ldots$ to classify the anomaly.}
\label{fig:reconstuction_LB}
\end{figure}

With this decision threshold, a confusion matrix is obtained in order to consider the autoencoder not only as a anomaly detector but also as a classifier and to provide results about classification metrics. The results are shown in Table \ref{confusion_matrix}. \\


\begin{table}[h!]
\centering
\begin{tabular}{llll}
                                                &                                 & \multicolumn{2}{c}{Real}                                       \\ \cline{3-4} 
                                                & \multicolumn{1}{l|}{}           & \multicolumn{1}{l|}{L. Bomb} & \multicolumn{1}{l|}{Healthy} \\ \cline{2-4} 
\multicolumn{1}{c|}{Predicted} & \multicolumn{1}{l|}{L. Bomb} & \multicolumn{1}{l|}{1629}       & \multicolumn{1}{l|}{174}     \\ \cline{2-4} 
\multicolumn{1}{c|}{}                           & \multicolumn{1}{l|}{Healthy}    & \multicolumn{1}{l|}{135}        & \multicolumn{1}{l|}{5457}    \\ \cline{2-4} 
\vspace{0.001cm}
\end{tabular}
\caption{Classification considering  $MSE>\alpha$ is infected.}
\label{confusion_matrix}
\end{table}

Then, a 10-fold cross validation is done and finally we get the following performance measures (mean of the 10-fold results), which usually are taken into account to determine the goodness of fit.

\begin{equation*}
\begin{aligned}
\hspace{-0.3cm} Accuracy  &= \hspace{0.5cm} \frac{\text{\tiny{Correctly classified}}}{\text{\tiny{Total of samples}}}           &= 0.9632 \\
\hspace{-0.3cm} Precision &=\frac{\text{\tiny{Correctly classified as infected}}}{\text{\tiny{Samples predicted as infected}}} &= 0.9335\\
\hspace{-0.3cm} Recall    &=\frac{\text{\tiny{Correctly classified as infected}}}{\text{\tiny{Samples actually are infected}}} &= 0.9136\\
\end{aligned}
\end{equation*}

These results show that our autoencoder model can classify states of the virtual machines using anomaly detection being trained just with one kind of data (healthy state).


\subsubsection{Neuroevolution results}

In this section we will present the most important results of this paper. We will see how a neural network trained with a hybrid machine learning algorithm with evolutionary algorithms is able to reduce the effect of these attacks on virtual instances. \\

In the Figure \ref{fig:reward_top_agent}, we can see how the Mean Square Error between the input data and the output provided by the autoenconder is reduced almost to zero which proves the desired result, i.e. the best agent is killing the malicious process, reducing the effect of the attack. \\






\begin{figure}[h!]
\includegraphics[scale=0.5]{figs/results/reward_best_agent_final.eps}
\vspace{-0.5cm}
\caption{MSE for the best agent in each generation using an algorithm to evolve neural networks}
\label{fig:reward_top_agent}
\end{figure}


On the other hand, an agent that kills all the processes will also reduce the effect of the threat, but the instance will be unusable which is not our goal. Therefore, we can see in Figure \ref{fig:processes_killed_top_agent} how the number of processes killed by the best agent are reduced in each generation, which means it is reducing the effect of the threat while killing the right process (malicious).\\

\begin{figure}[h!]
\includegraphics[scale=0.5]{figs/results/number_process_final_top_agent.eps}
\vspace{-0.5cm}
\caption{MSE for the best agent in each generation using an algorithm to evolve neural networks}
\label{fig:processes_killed_top_agent}
\end{figure}


\section{Conclusions}

In this paper we have shown other way to reduce the effect of cyber attacks and as well as another application that has the neuroevolution algorithms who has never applied in cyber security. We have confimed the results of other researchers \cite{autoencoderdos} using an autoencoder to classify cyber attacks, although in our case we have used other methodology and other cyber attack. The autoencoders can give you a measure of how close to a healthy state a virtual instance is, this allow us to combine this measure with a neuroevolution algorithm to select the best agents, giving as a result an ingenious hybrid algorithm able to detect malicious processes that are being running in a shell. 

\newpage

\appendix
\section{Appendix: Description of each variable}\label{appx_variables}

\subsection{Central Processing Unit (CPU) Features}

\textbf{cpu\_cores:} The number of CPU cores present on the host. The non-normalized percentages will have a maximum value of 100\% $\cdot$ cores. The normalized percentages already take this value into account and have a maximum value of 100\%.\\

\textbf{cpu\_user\_pct:} The percentage of CPU time spent in user space. On multi-core systems, you can have percentages that are greater than 100\%. For example, if 3 cores are at 60\% use, then the system.cpu.user.pct will be 180\%.\\

\textbf{cpu\_system\_pct:} The percentage of CPU time spent in kernel space.\\

\textbf{cpu\_nice\_pct:} The percentage of CPU time spent on low-priority processes.\\

\textbf{cpu\_idle\_pct:} The percentage of CPU time spent idle.\\

\textbf{cpu\_iowait\_pct:} The percentage of CPU time spent in wait (on disk).\\

\textbf{cpu\_irq\_pct:} The percentage of CPU time spent servicing and handling hardware interrupts.\\

\textbf{cpu\_softirq\_pct:} The percentage of CPU time spent servicing and handling software interrupts.\\

\textbf{cpu\_steal\_pct:} The percentage of CPU time spent in involuntary wait by the virtual CPU while the hypervisor was servicing another processor.\\

\textbf{cpu\_total\_pct:} The percentage of CPU time spent in states other than Idle and IOWait.\\


\subsection{Core features}

\textbf{core\_user\_pct:} The percentage of CPU time spent in user space.\\

\textbf{core\_system\_pct:} The percentage of CPU time spent in kernel space.\\

\textbf{core\_nice\_pct:} The percentage of CPU time spent on low-priority processes.\\

\textbf{core\_idle\_pct:} The percentage of CPU time spent idle..\\

\textbf{core\_iowait\_pct:} The percentage of CPU time spent in wait (on disk).\\

\textbf{core\_irq\_pct:} The percentage of CPU time spent servicing and handling hardware interrupts.\\

\textbf{core\_softirq\_pct:}The percentage of CPU time spent servicing and handling software interrupts.\\

\textbf{core\_steal\_pct:}  The percentage of CPU time spent in involuntary wait by the virtual CPU while the hypervisor was servicing another processor. Available only on Unix.


\subsection{Disk Input/Output (Disk I/O) features}

\textbf{diskio\_read\_count:} The total number of reads completed successfully.\\

\textbf{diskio\_write\_count:} The total number of writes completed successfully.\\

\textbf{diskio\_read\_bytes:} The total number of bytes read successfully. On Linux this is the number of sectors read multiplied by an assumed sector size of 512.\\

\textbf{diskio\_write\_bytes:} The total number of bytes written successfully. On Linux this is the number of sectors written multiplied by an assumed sector size of 512.\\

\textbf{diskio\_read\_time:} The total number of milliseconds spent by all reads.\\

\textbf{diskio\_write\_time:} The total number of milliseconds spent by all writes.\\

\textbf{diskio\_io\_time:} The total number of of milliseconds spent doing I/Os.\\

\textbf{diskio\_iostat\_read\_request\_merges\_per\_sec:} The number of read requests merged per second that were queued to the device.\\

\textbf{diskio\_iostat\_write\_request\_merges\_per\_sec:} The number of write requests merged per second that were queued to the device.\\

\textbf{diskio\_iostat\_read\_request\_per\_sec:} The number of read requests that were issued to the device per second.\\

\textbf{diskio\_iostat\_wirte\_request\_per\_sec:} The number of write requests that were issued to the device per second.\\

\textbf{diskio\_iostat\_read\_per\_sec\_bytes:} The number of Bytes read from the device per second.\\

\textbf{diskio\_iostat\_read\_await:} The average time spent for read requests issued to the device to be served.\\

\textbf{diskio\_iostat\_write\_per\_sec\_bytes:}  The number of Bytes write from the device per second.\\

\textbf{diskio\_iostat\_write\_await:} The average time spent for write requests issued to the device to be served.\\

\textbf{diskio\_iostat\_request\_avg\_size:} The average size (in bytes) of the requests that were issued to the device.\\

\textbf{diskio\_iostat\_queue\_avg\_size:}The average queue length of the requests that were issued to the device.\\

\textbf{diskio\_iostat\_await:} The average time spent for requests issued to the device to be served.\\

\textbf{diskio\_iostat\_service\_time:} The average service time (in milliseconds) for I/O requests that were issued to the device.\\

\textbf{diskio\_iostat\_busy:} Percentage of CPU time during which I/O requests were issued to the device (bandwidth utilization for the device). Device saturation occurs when this value is close to 100\%.\\


\subsection{Entropy}

\textbf{entropy\_available\_bits:} The available bits of entropy.\\

\textbf{entropy\_pct:} The percentage of available entropy, relative to the pool size of 4096.\\



\subsection{Filesystem}

\textbf{filesystem\_available:} The disk space available to an unprivileged user in bytes.\\

\textbf{filesystem\_files:} The total number of file nodes in the file system.\\

\textbf{filesystem\_free:} The disk space available in bytes.\\

\textbf{filesystem\_free\_files:} The number of free file nodes in the file system.\\

\textbf{filesystem\_total:} The total disk space in bytes.\\

\textbf{filesytem\_used\_bytes:} The used disk space in bytes.\\

\textbf{filesystem\_used\_pct:} The percentage of used disk space.\\

\textbf{fsstat\_count:} Number of file systems found.\\

\textbf{fsstat\_total\_files:} Total number of files.\\

\textbf{fsstat\_total\_size\_free:} Total free space.\\

\textbf{fsstat\_total\_size\_used:} Total used space.\\

\textbf{fsstat\_total\_size\_total:} Total space (used plus free).\\

\subsection{Memory Swap}

\textbf{memory\_swap\_pct:} Total swap memory.\\

\textbf{memory\_swap\_used\_bytes:} Used swap memory in bytes.\\

\textbf{memory\_swap\_free:} Available swap memory.\\

\textbf{memory\_swap\_used\_pct:} The percentage of used swap memory.\\


\subsection{Memory hugepages}

\textbf{memory\_hugepages\_total:} Number of huge pages in the pool.\\

\textbf{memory\_hugepages\_used\_bytes:} Memory used in allocated huge pages in bytes.\\

\textbf{memory\_hugepages\_used\_pct:} Percentage of huge pages used.\\

\textbf{memory\_hugepages\_free:} Number of available huge pages in the pool.\\

\textbf{memory\_hugepages\_reserved:} Number of reserved but not allocated huge pages in the pool.\\

\textbf{memory\_hugepages\_surplus:} Number of overcommited huge pages.\\

\textbf{memory\_hugepages\_default\_size:} Default size for huge pages.




\subsection{Socket summary}

\textbf{socket\_summary\_all\_count:} All open connections.\\

\textbf{socket\_summary\_all\_listening:} All listening ports.\\

\textbf{socket\_summary\_tcp\_memory:} Memory used by  \textit{Transmission Control Protocol} (TCP) sockets in bytes, based on number of allocated pages and system page size. \\

\textbf{socket\_summary\_tcp\_all\_orphan:} A count of all orphaned tcp sockets.\\

\textbf{socket\_summary\_tcp\_all\_count:} All open TCP connections.\\

\textbf{socket\_summary\_tcp\_all\_listening:} All TCP listening ports.\\

\textbf{socket\_summary\_tcp\_all\_established:} Number of established TCP connections.\\

\textbf{socket\_summary\_tcp\_all\_close\_wait:} Number of TCP connections in \textit{close\_wait} state.\\

\textbf{socket\_summary\_tcp\_all\_time\_wait:} Number of TCP connections in \textit{time\_wait} state.\\

\textbf{socket\_summary\_udp\_memory:} Memory used by UDP sockets in bytes, based on number of allocated pages and system page size.\\

\textbf{socket\_summary\_udp\_all\_count:} All open UDP connections.\\


%================== Appendix II =====================% 

\section{Appendix: Description of each variable for the agents.}


\subsubsection{File descriptors}

\textbf{process\_fd\_limit\_hard:} limit hard on the number of file descriptors opened by the process. The hard limit can only be increased by root.\\

\textbf{process\_fd\_limit\_soft:} limit soft on the number of file descriptors opened by the process. The process can change the limit soft at any time.\\

\textbf{process\_fd\_open:} the number of file descriptors opened by the process.\\


\subsubsection{Central Processing Unit (CPU)}

\textbf{process\_cpu\_total\_norm\_pct:} Percentage of CPU time that the process consumes since the last event. This value is normalized by the number of CPU cores and ranges from 0\% to 100\%.\\

\subsubsection{Memory}

\textbf{process\_memory\_size:} The total in bytes of virtual memory that the process has.\\

\textbf{process\_memory\_rss\_bytes:} The Resident Set Size (RSS) in bytes. The proportion of memory used by a process that is held in main memory (RAM), that is, the memory that the process occupied in main memory or RAM.\\

\textbf{process\_memory\_share:} the shared memory in bytes that the process uses.\\

\subsubsection{Temporal features}

\textbf{process\_cpu\_start\_time\_seconds:} The time (in seconds) since the process started.\\





\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{references} % Entries are in the refs.bib file


%% Loading bibliography style file
%\bibliographystyle{model1-num-names}
%\bibliographystyle{iosart2c}

% Loading bibliography database
%\bibliography{iosart2c}



\end{document}
